y
myX<- seq(-3, 3, 0.5)
myX
myCDF<-cdf.hy()
pnorm(0.5)
1-pnorm(1)
pnorm(1.2) - pnorm(0.2)
pnorm(1)-pnprm(-1)
pnorm(1)-pnorm(-1)
1- pnorm(1)+pnorm(0.6)
?dnorm
?pnorm
pnorm(1200, 930,140)
pnorm(1.93) – pnorm(-6.64)
pnorm(1.93) – pnorm(-6.64)
pnorm(1.93)-pnorm(-6.64)
pnorm(2.5)-pnorm(-1.5)
1-pnorm(1)+pnorm(-1)
1-pnorm(1.93)
knitr::opts_chunk$set(echo = TRUE)
# Simulate an AR model with 0.5 slope
x <- arima.sim(model =list(ar=0.5), n = 100)
# Simulate an AR model with 0.9 slope. Slope 0.9 will increase the autocorrelation
y <- arima.sim(model=list(ar=0.9), n=100)
# Simulate an AR model with -0.75 slope, negative slope will create an oscilative model
z <- arima.sim(model=list(ar=-0.75),n=100)
# Plot your simulated data
plot.ts(cbind(x, y, z))
# Calculate the ACF for x
acf(x)
# Calculate the ACF for y
acf(y)
# Calculate the ACF for z
acf(z)
# Simulate and plot AR model with slope 0.9
x <- arima.sim(model = list(ar=0.9), n = 200)
ts.plot(x)
acf(x)
# Simulate and plot AR model with slope 0.98: higher persistence when its slope parameter is closer to 1
y <- arima.sim(model= list(ar=0.98), n=200)
ts.plot(y)
acf(y)
# Simulate and plot RW model: slope is close to 1, strong persistence
z <- arima.sim(model= list(order=c(0,1,0)), n=200)
ts.plot(z)
acf(z)
# Fit the AR model to x
arima(x, order = c(1,0,0))
# Copy and paste the slope (ar1) estimate
#0.8575
# Copy and paste the slope mean (intercept) estimate
#-0.0948
# Copy and paste the innovation variance (sigma^2) estimate
#1.022
# Fit the AR model to AirPassengers
AR <-arima(AirPassengers, order = c(1,0,0))
print(AR)
# Run the following commands to plot the series and fitted values
ts.plot(AirPassengers)
AR_fitted <- AirPassengers - residuals(AR)
points(AR_fitted, type = "l", col = 2, lty = 2)
# Fit an AR model to Nile
AR_fit <-arima(Nile, order  = c(1,0,0))
print(AR_fit)
# Use predict() to make a 1-step forecast
predict_AR <- predict(AR_fit)
# Obtain the 1-step forecast using $pred[1]
predict_AR$pred[1]
# Use predict to make 1-step through 10-step forecasts
predict(AR_fit, n.ahead = 10)
# Run to plot the Nile series plus the forecast and 95% prediction intervals
ts.plot(Nile, xlim = c(1871, 1980))
AR_forecast <- predict(AR_fit, n.ahead = 10)$pred
AR_forecast_se <- predict(AR_fit, n.ahead = 10)$se
points(AR_forecast, type = "l", col = 2)
points(AR_forecast - 2*AR_forecast_se, type = "l", col = 2, lty = 2)
points(AR_forecast + 2*AR_forecast_se, type = "l", col = 2, lty = 2)
knitr::opts_chunk$set(echo = TRUE)
# Simulate an AR model with 0.5 slope
x <- arima.sim(model =list(ar=0.5), n = 100)
# Simulate an AR model with 0.9 slope. Slope 0.9 will increase the autocorrelation
y <- arima.sim(model=list(ar=0.9), n=100)
# Simulate an AR model with -0.75 slope, negative slope will create an oscilative model
z <- arima.sim(model=list(ar=-0.75),n=100)
# Plot your simulated data
plot.ts(cbind(x, y, z))
# Calculate the ACF for x
acf(x)
# Calculate the ACF for y
acf(y)
# Calculate the ACF for z
acf(z)
# Simulate and plot AR model with slope 0.9
x <- arima.sim(model = list(ar=0.9), n = 200)
ts.plot(x)
acf(x)
# Simulate and plot AR model with slope 0.98: higher persistence when its slope parameter is closer to 1
y <- arima.sim(model= list(ar=0.98), n=200)
ts.plot(y)
acf(y)
# Simulate and plot RW model: slope is close to 1, strong persistence
z <- arima.sim(model= list(order=c(0,1,0)), n=200)
ts.plot(z)
acf(z)
knitr::opts_chunk$set(echo = TRUE)
install.packages(zoo, xts)
install.packages("zoo", "xts")
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
x <- arima.sim(n = 10000, list(ar = -0.6, ma = 0.5))
coef(arima(x, order = c(1, 0, 1)))
x.ma <- arima(x.ts, order = c(0, 0, 1)) #MA(1) model
x.ts<- ts(x)
x.ma <- arima(x.ts, order = c(0, 0, 1)) #MA(1) model
x.ar <- arima(x.ts, order = c(1, 0, 0)) #AR(1) model
x.arma <- arima(x.ts, order = c(1, 0, 1)) #ARMA(1,1)
#Compare AICs
AIC(x.ma)
AIC(x.ar)
AIC(x.arma)
x.ts<- ts(x)
x.ma <- arima(x.ts, order = c(0, 0, 1)) #MA(1) model
x.ar <- arima(x.ts, order = c(1, 0, 0)) #AR(1) model
x.arma <- arima(x.ts, order = c(1, 0, 1)) #ARMA(1,1)
#Compare AICs
AIC(x.ma)
AIC(x.ar)
AIC(x.arma) # the best fit
x.arma
acf(resid(x.arma)) #show residuals
www <- "http://www.massey.ac.nz/~pscowper/ts/cbe.dat"
CBE <- read.table(www, header = T)
setwd("~/")
setwd("~/GitHub/TimeSeriesR-DataAnalytics/Code/Cheatsheets")
www <- "../../Data/cbe.dat"
CBE <- read.table(www, header = T)
Elec.ts <- ts(CBE[, 3], start = 1958, freq = 12)
Time <- 1:length(Elec.ts)
Imth <- cycle(Elec.ts)
Elec.lm <- lm(log(Elec.ts) ~ Time + I(Time^2) + factor(Imth))
acf(resid(Elec.lm))
#Find best order
best.order <- c(0, 0, 0) #initial value
best.aic <- Inf # defalt to infinity
for (i in 0:2) for (j in 0:2) {
fit.aic <- AIC(arima(resid(Elec.lm), order = c(i, 0,j)))
if (fit.aic < best.aic) {
best.order <- c(i, 0, j)
best.arma <- arima(resid(Elec.lm), order = best.order)
best.aic <- fit.aic
}
}
best.order #show best.order
acf(resid(best.arma))
knitr::opts_chunk$set(echo = TRUE)
fc <- naive(oil)
install.packages("fpp2")
library(fpp2)
fc <- naive(oil)
autoplot(oil, series = "Data") + xlab("Year") +
autolayer(fitted(fc), series = "Fitted") +
ggtitle("Oil production in Saudi Arabia")
set.seed(3) # Reproducibility
wn <- ts(rnorm(36)) # Create White noise
autoplot(wn) # Plot!
ggAcf(wn) +
ggtitle("Sample ACF for white noise")
autoplot(pigs/1000) +
xlab("Year") +
ylab("thousands") +
ggtitle("Monthly number of pigs slaughtered in Victoria")
ggAcf(pigs) +
ggtitle("ACF of monthly pigs slaughtered in Victoria")
Box.test(pigs, lag = 24, fitdf = 0, type = "Lj")
fc <- naive(oil)
autoplot(oil, series = "Data") + xlab("Year") +
autolayer(fitted(fc), series = "Fitted") +
ggtitle("Oil production in Saudi Arabia")
#Residuals
autoplot(residuals(fc))
checkresiduals(fc)
training <- window(oil, end = 2003)
test <- window(oil, start = 2004)
fc_train <- naive(training, h = 10)
autoplot(fc_train) +
autolayer(test, series = "Test data")
accuracy(fc_train, test)
accuracy(fc_train, test)
e <- tsCV (oil, forecastfunction = naive, h = 1) #h=1 give the same results as residuals
mean(e^2 , na.rm = TRUE)
e <- tsCV (oil, forecastfunction = naive, h = 1) #h=1 give the same results as residuals
mean(e^2 , na.rm = TRUE)
#Calcukate MSE
sq <- function(u){u^2}
for(h in 1:10)
{
oil %>% tsCV(forecastfunction = naive, h = h) %>%
sq() %>% mean(na.rm = TRUE) %>% print()
}
#Initial data
autoplot(usmelec) +
xlab("Year") + ylab("") +
ggtitle("US monthly net electricity generation")
#Square Root (^0.5)
autoplot(usmelec^0.5) +
xlab("Year") + ylab("") +
ggtitle("Square root electricity generation")
#Cube Root (^0.33333)
autoplot(usmelec^0.33333) +
xlab("Year") + ylab("") +
ggtitle("Cube root electricity generation")
#Log()
autoplot(log(usmelec)) +
xlab("Year") + ylab("") +
ggtitle("Log electricity generation")
#Inverse (-1/data)
autoplot(-1/usmelec) +
xlab("Year") + ylab("") +
ggtitle("Inverse electricity generation")
BoxCox.lambda(usmelec)
#Back transformation
usmelec %>%
ets(lambda = -0.57) %>%
forecast(h = 60) %>%
autoplot()
autoplot(usnetelec) +
xlab("Year") +
ylab("billion kwh") +
ggtitle("US net electricity generation")
fit <- auto.arima(usnetelec)
summary(fit)
fit %>% forecast() %>% autoplot()
autoplot(debitcards) +
xlab("Year") + ylab("million ISK") +
ggtitle("Retail debit card usage in Iceland")
fit <- auto.arima(debitcards, lambda = 0)
fit #Check ARIMA
fit %>%
forecast(h = 12) %>%
autoplot() + xlab("Year")
fit %>%
forecast(h = 24) %>%
autoplot() + xlab("Year")
x.ts<- ts(x)
x.ma <- arima(x.ts, order = c(0, 0, 1)) #MA(1) model
x.ar <- arima(x.ts, order = c(1, 0, 0)) #AR(1) model
x.arma <- arima(x.ts, order = c(1, 0, 1)) #ARMA(1,1)
#Compare AICs
AIC(x.ma)
AIC(x.ar)
AIC(x.arma) # the best fit
x.arma #arima(x = x.ts, order = c(1, 0, 1))
acf(resid(x.arma)) #show correlogram of residuals for the ARMA(1, 1) model fitted
www <- "../../Data/cbe.dat" #load data
CBE <- read.table(www, header = T)
Elec.ts <- ts(CBE[, 3], start = 1958, frequency = 12) #use monthly data
Time <- 1:length(Elec.ts)
Imth <- cycle(Elec.ts)
Elec.lm <- lm(log(Elec.ts) ~ Time + I(Time^2) + factor(Imth)) #A regression model is fitted to the logarithms of the original series
acf(resid(Elec.lm)) #correlogram of residuals
x.ts<- ts(x)
x.ma <- arima(x.ts, order = c(0, 0, 1)) #MA(1) model
x.ar <- arima(x.ts, order = c(1, 0, 0)) #AR(1) model
x.arma <- arima(x.ts, order = c(1, 0, 1)) #ARMA(1,1)
#Compare AICs
AIC(x.ma)
AIC(x.ar)
AIC(x.arma)
x.arma
acf(resid(x.arma)) #show correlogram of residuals for the ARMA(1, 1) model fitted
www <- "../../Data/cbe.dat" #load data
CBE <- read.table(www, header = T)
Elec.ts <- ts(CBE[, 3], start = 1958, frequency = 12) #use monthly data
Time <- 1:length(Elec.ts)
Imth <- cycle(Elec.ts)
Elec.lm <- lm(log(Elec.ts) ~ Time + I(Time^2) + factor(Imth)) #A regression model is fitted to the logarithms of the original series
acf(resid(Elec.lm)) #correlogram of residuals
#Find best order
best.order <- c(0, 0, 0) #initial value
best.aic <- Inf # default to infinity
for (i in 0:2) for (j in 0:2)
{
fit.aic <- AIC(arima(resid(Elec.lm), order = c(i, 0,j)))
if (fit.aic < best.aic)
{
best.order <- c(i, 0, j)
best.arma <- arima(resid(Elec.lm), order = best.order)
best.aic <- fit.aic
}
}
best.order #show best.order
acf(resid(best.arma))
new.time <- seq(length(Elec.ts), length = 36)
new.data <- data.frame(Time = new.time, Imth = rep(1:12,3)) # requires data frame
#Type lm
predict.lm <- predict(Elec.lm, new.data) #requires new data
#Type arma
predict.arma <- predict(best.arma, n.ahead = 36) #requires number of time steps to forecast
elec.pred <- ts(exp(predict.lm + predict.arma$pred), start = 1991,frequency = 12)
ts.plot(cbind(Elec.ts, elec.pred), lty = 1:2) #combine data with predicted values
www <- "https://github.com/AtefOuni/ts/blob/master/Data/wave.dat"
wave.dat <- read.table(www, header = T)
www <- "../../Data/wave.dat" #load data
wave.dat <- read.table(www, header = T)
attach (wave.dat)
layout(1:3)
plot (as.ts(waveht), ylab = 'Wave height')
acf (waveht)
pacf (waveht)
wave.arma <- arima(waveht, order = c(4,0,4))
acf (wave.arma$res[-(1:4)])
pacf (wave.arma$res[-(1:4)])
hist(wave.arma$res[-(1:4)], xlab='height / mm', main='')
www <- "../../Data/wave.dat" #load data
wave.dat <- read.table(www, header = T)
attach (wave.dat)
layout(1:3)
plot (as.ts(waveht), ylab = 'Wave height')
acf (waveht)
pacf (waveht)
www <- "../../Data/wave.dat" #load data
wave.dat <- read.table(www, header = T)
attach (wave.dat)
layout(1:3)
plot (as.ts(waveht), ylab = 'Wave height')
acf (waveht)
pacf (waveht)
wave.arma <- arima(waveht, order = c(4,0,4))
acf (wave.arma$res[-(1:4)])
pacf (wave.arma$res[-(1:4)])
hist(wave.arma$res[-(1:4)], xlab='height / mm', main='')
www <- "../../Data/cbe.dat" #load data
CBE <- read.table(www, header = T)
Ch.ts <- ts(CBE[, 1], start = 1958, frequency = 12) #use monthly data
ch <- naive(Ch.ts)
autoplot(Ch.ts, series = "Data") + xlab("Year") +
autolayer(fitted(ch), series = "Fitted") +
ggtitle("Chocolate Consumption")
#Residuals
autoplot(residuals(ch))
www <- "../../Data/cbe.dat" #load data
CBE <- read.table(www, header = T)
Ch.ts <- ts(CBE[, 1], start = 1958, frequency = 12) #use monthly data
ch <- naive(Ch.ts)
autoplot(Ch.ts, series = "Data") + xlab("Year") +
autolayer(fitted(ch), series = "Fitted") +
ggtitle("Chocolate Consumption")
#Residuals
autoplot(residuals(ch))
checkresiduals(ch)
checkresiduals(fc)
frequency(Ch.ts)
train_ch <- window(Ch.ts, end = 1980) #training data
test_ch <- window(Ch.ts, start = 1981)   #test data
ch_train <- naive(train_ch, h = 10) #observed value
autoplot(ch_train) +
autolayer(test_ch, series = "Test data") # red line of actual test data
frequency(Ch.ts)
train_ch <- window(Ch.ts, end = c(1980,12)) #training data
test_ch <- window(Ch.ts, start = c(1981,1))   #test data
ch_train <- naive(train_ch, h = 10) #observed value
autoplot(ch_train) +
autolayer(test_ch, series = "Test data") # red line of actual test data
frequency(Ch.ts)
train_ch <- window(Ch.ts, end = 1980) #training data
test_ch <- window(Ch.ts, start = 1981)   #test data
ch_train <- naive(train_ch, h = 10) #observed value
autoplot(ch_train) +
autolayer(test_ch, series = "Test data") # red line of actual test data
frequency(Ch.ts)
train_ch <- window(Ch.ts, end = 1980) #training data
test_ch <- window(Ch.ts, start = 1981)   #test data
ch_train <- naive(train_ch, h = 5) #observed value
autoplot(ch_train) +
autolayer(test_ch, series = "Test data") # red line of actual test data
frequency(Ch.ts)
train_ch <- window(Ch.ts, end = c(1980,12)) #training data
test_ch <- window(Ch.ts, start = c(1981,1))   #test data
ch_train <- naive(train_ch, h = 5) #observed value
autoplot(ch_train) +
autolayer(test_ch, series = "Test data") # red line of actual test data
frequency(Ch.ts)
train_ch <- window(Ch.ts, end = c(1980,12)) #training data
test_ch <- window(Ch.ts, start = c(1981,1))   #test data
ch_train <- naive(train_ch, h = 100) #observed value
autoplot(ch_train) +
autolayer(test_ch, series = "Test data") # red line of actual test data
?accuracy
accuracy(fc_train, test)
accuracy(ch_train, test_ch)
#Generate and plot AR
x <- arima.sim(list(order = c(2, 0, 0), ar = c(0, -0.9)), n = 100)
plot(x, main="AR(2)")
knitr::opts_chunk$set(echo = TRUE)
#Use astsa package
library(astsa)
data()                     # use this command to view all the loaded data
#Convert dataset to ts using Monthly price of a pound of chicken
tsData = ts(chicken, frequency = 12)
components.ts = decompose(tsData)
plot(components.ts)
stationary.ts = diff(tsData)
plot(stationary.ts)
#cor.test(tsData, lag(tsData, -1))
#cor.test(tsData, lag(tsData, -6))
#To remove seasonality from the data, we subtract the seasonal component from the original series
seasonally_adj.ts <- tsData - components.ts$seasonal
#difference it to make it stationary
stationary.ts <- diff(seasonally_adj.ts, differences=1)
plot(stationary.ts)
acf(stationary.ts, lag.max=34)
pacf(stationary.ts, lag.max=34)
fitARIMA <- arima(tsData, order=c(1,1,1),seasonal = list(order = c(1,0,0), period = 12),method="ML")
library(lmtest)
coeftest(fitARIMA)
#Remove insignificant coefficients
confint(fitARIMA)
acf(fitARIMA$residuals)
library(FitAR)
boxresult <- LjungBoxTest (fitARIMA$residuals,k=2,StartLag=1)
plot(boxresult[,3],main= "Ljung-Box Q Test", ylab= "P-values", xlab= "Lag")
qqnorm(fitARIMA$residuals)
qqline(fitARIMA$residuals)
library(forecast)
#Find the best model
auto.arima(tsData, trace=TRUE)
#n.ahead specifies the number of steps to predict
predict(fitARIMA,n.ahead = 5)
#Generate and plot MA
x <- arima.sim(list(order = c(0, 0, 1), ma = 0.9), n = 100)
plot(x, main="MA(1)")
#Generate and plot AR
x <- arima.sim(list(order = c(2, 0, 0), ar = c(0, -0.9)), n = 100)
plot(x, main="AR(2)")
#Estimate AR(2) with mean =50
x <- arima.sim(list(order = c(2, 0, 0),ar = c(1.5, -.75)),n = 200) + 50
#Analysis of residuals
x_fit <- sarima(x, p = 2, d = 0, q = 0)
x_fit$ttable
#Estimate MA(1) with mean=0
y <- arima.sim(list(order = c(0, 0, 1), ma = -.7), n = 200)
y_fit <- sarima(y, p = 0, d = 0, q = 1)
y_fit$ttable
tsData_diff <- diff(log(tsData))
#AR(1) residual analysis
sarima(tsData_diff, p = 1, d = 0, q = 0)
#MA(2)residual analysis
sarima(tsData_diff, p = 0, d = 0, q = 2)
# ARIMA(p = 1, d = 1, q = 0)
x <- arima.sim(list(order = c(1, 1, 0), ar = .9), n = 200)
plot(x, main = "ARIMA(p = 1, d = 1, q = 0)")
plot(diff(x), main = "ARMA(p = 1, d = 0, q = 0)")
x <- arima.sim(list(order = c(1, 1, 0), ar = .9), n = 200)
#Plot ACF (autocorrelation function) and PACF of the ARIMA model
acf2(x)
x <- arima.sim(list(order = c(1, 1, 0), ar = .9), n = 200)
#Use differenced data
acf2(diff(x))
set.seed(1)
x <- arima.sim(n = 10000, list(ar = -0.6, ma = 0.5)) #simulate ARMA model
coef(arima(x, order = c(1, 0, 1))) #Find AR and MA coefficients of fitted ARMA(1, 1) model based on the simulated series x
x.ts<- ts(x)
x.ma <- arima(x.ts, order = c(0, 0, 1)) #MA(1) model
x.ar <- arima(x.ts, order = c(1, 0, 0)) #AR(1) model
x.arma <- arima(x.ts, order = c(1, 0, 1)) #ARMA(1,1)
#Compare AICs
AIC(x.ma)
AIC(x.ar)
AIC(x.arma)
x.arma
acf(resid(x.arma)) #show correlogram of residuals for the ARMA(1, 1) model fitted
www <- "../../Data/cbe.dat" #load data
CBE <- read.table(www, header = T)
Elec.ts <- ts(CBE[, 3], start = 1958, frequency = 12) #use monthly data
Time <- 1:length(Elec.ts)
Imth <- cycle(Elec.ts)
Elec.lm <- lm(log(Elec.ts) ~ Time + I(Time^2) + factor(Imth)) #A regression model is fitted to the logarithms of the original series
acf(resid(Elec.lm)) #correlogram of residuals
#Find best order with for loop with upper bounds on p and q – taken as 2
best.order <- c(0, 0, 0) #initial value
best.aic <- Inf # default to infinity
for (i in 0:2) for (j in 0:2)
{
fit.aic <- AIC(arima(resid(Elec.lm), order = c(i, 0,j)))
if (fit.aic < best.aic)
{
best.order <- c(i, 0, j)
best.arma <- arima(resid(Elec.lm), order = best.order)
best.aic <- fit.aic
}
}
best.order #show best.order
acf(resid(best.arma))
new.time <- seq(length(Elec.ts), length = 36)
new.data <- data.frame(Time = new.time, Imth = rep(1:12,3)) # requires data frame
#Type lm
predict.lm <- predict(Elec.lm, new.data) #requires new data
#Type arma
predict.arma <- predict(best.arma, n.ahead = 36) #requires number of time steps to forecast
elec.pred <- ts(exp(predict.lm + predict.arma$pred), start = 1991,frequency = 12)
ts.plot(cbind(Elec.ts, elec.pred), lty = 1:2) #combine data with predicted values
www <- "../../Data/wave.dat" #load data
wave.dat <- read.table(www, header = T)
attach (wave.dat)
layout(1:3)
plot (as.ts(waveht), ylab = 'Wave height')
acf (waveht)
pacf (waveht)
wave.arma <- arima(waveht, order = c(4,0,4))
acf (wave.arma$res[-(1:4)])
pacf (wave.arma$res[-(1:4)])
hist(wave.arma$res[-(1:4)], xlab='height / mm', main='')
