---
title: "datacamp_TS4_AutoRegressiveModels"
author: "Helen Yezerets"
date: "February 7, 2019"
output: html_document
tags: AR (autoregressive model), acf with lags, Persistence 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##References
Matteson, D. S. (2019). *Introduction to Time Series Analysis*. Retrieved from https://www.datacamp.com/courses/introduction-to-time-series-analysis

##Simulate the autoregressive model
The autoregressive (AR) model is arguably the **most widely used** time series model. It shares the very familiar interpretation of a simple linear regression, but here **each observation is regressed on the previous observation**. 

The AR model also **includes the white noise (WN) and random walk (RW) models** examined in earlier chapters as special cases.

The versatile **arima.sim()** function used for WN and RW can also be used to simulate data from an AR model by setting the **model =list(ar = phi), n= length of series** , in which **phi** is a slope parameter from the interval (-1, 1). We also need to specify a series length n.(example: arima.sim(model =list(ar=0.5), n = 100)

###Examples:
```{r}
# Simulate an AR model with 0.5 slope
x <- arima.sim(model =list(ar=0.5), n = 100)

# Simulate an AR model with 0.9 slope. Slope 0.9 will increase the autocorrelation
y <- arima.sim(model=list(ar=0.9), n=100)

# Simulate an AR model with -0.75 slope, negative slope will create an oscilative model
z <- arima.sim(model=list(ar=-0.75),n=100)

# Plot your simulated data
plot.ts(cbind(x, y, z))

```

###Analysis:

+ x data shows a just a moderate amount of autocorrelation 
+ y data shows a **large amount of autocorrelation**
+ z data tends to **oscillate** considerably from one observation to the next.

##Estimate the autocorrelation function (ACF) for an autoregression
The **acf()** command estimates autocorrelation by exploring lags in the data (the relationship between the current observation and lags extending backwards). **By default, this command generates a plot**.

###Examples:

```{r}
# Calculate the ACF for x
acf(x)

# Calculate the ACF for y
acf(y)

# Calculate the ACF for z
acf(z)

```

###Analysis:

+ The first series x has **positive autocorrelation for the first couple lags**, but they quickly approach zero. 
+ The second series y has **positive autocorrelation for many lags**, but they also decay to zero. 
+ The last series z has an **alternating pattern**, as does its autocorrelation function (ACF), but its ACF still quickly decays to zero in magnitude.

##Persistence and anti-persistence
Autoregressive processes can exhibit varying levels of persistence as well as anti-persistence or oscillatory behavior.

+ **Persistence** is defined by a **high correlation** between an observation and its lag. Clear downward trend over time shows a very high degree of persistence in y series.
+ **anti-persistence** is defined by a **large amount of variation** between an observation and its lag (z series)

##Compare the random walk (RW) and autoregressive (AR) models
The random walk (RW) model is a **special case of the autoregressive (AR) model**, in which the **slope parameter is equal to 1**. 
The RW model is **not stationary** and exhibits **very strong persistence**. 
Its sample autocovariance function (ACF) also **decays to zero very slowly**, meaning past values have a **long lasting impact on current values**.

The AR model is **stationary** with a slope parameter between -1 and 1. The AR model exhibits higher persistence when its slope parameter is closer to 1, but the process **reverts to its mean** fairly quickly. 
Its sample ACF also decays to zero at a **quick (geometric) rate**, indicating that values far in the past have **little impact on future values** of the process.

###Examples:
```{r}
# Simulate and plot AR model with slope 0.9 
x <- arima.sim(model = list(ar=0.9), n = 200)
ts.plot(x)
acf(x)

# Simulate and plot AR model with slope 0.98: higher persistence when its slope parameter is closer to 1
y <- arima.sim(model= list(ar=0.98), n=200)
ts.plot(y)
acf(y)

# Simulate and plot RW model: slope is close to 1, strong persistence
z <- arima.sim(model= list(order=c(0,1,0)), n=200)
ts.plot(z)
acf(z)

```


###Analysis:

+ The AR model represented by series y exhibits greater persistence than series x, but the ACF continues to decay to 0. 
+ By contrast, the RW model represented by series z shows considerable persistence and relatively **little decay** in the ACF.
 
##Estimate the autoregressive (AR) model
For a given time series x we can fit the autoregressive (AR) model using the **arima()** command and setting order equal to c(1, 0, 0). Note for reference that an AR model is an **arima(1, 0, 0)** model.

arima() command allows to identify 

+ the estimated slope (ar1), 
+ mean (intercept), and 
+ innovation variance (sigma^2) of the model.

###Examples:
```{r}
# Fit the AR model to x
arima(x, order = c(1,0,0))

# Copy and paste the slope (ar1) estimate
#0.8575

# Copy and paste the slope mean (intercept) estimate
#-0.0948

# Copy and paste the innovation variance (sigma^2) estimate
#1.022

# Fit the AR model to AirPassengers
AR <-arima(AirPassengers, order = c(1,0,0))
print(AR)

# Run the following commands to plot the series and fitted values
ts.plot(AirPassengers)
AR_fitted <- AirPassengers - residuals(AR)
points(AR_fitted, type = "l", col = 2, lty = 2)


```

##Simple forecasts from an estimated AR model
Now that you've **modeled your data** using the arima() command, you are ready to make simple forecasts based on your model. The predict() function can be used **to make forecasts from an estimated AR model**. 
In the object generated by your predict() command:

+ $pred value is the forecast, and  
+ $se value is the standard error for the forceast.

To make predictions for several periods beyond the last observations, you can use the **n.ahead** argument in your predict() command. This argument establishes the **forecast horizon (h)**, or the number of periods being forecast. The forecasts are made recursively from 1 to h-steps ahead from the end of the observed time series.

```{r}
# Fit an AR model to Nile
AR_fit <-arima(Nile, order  = c(1,0,0))
print(AR_fit)

# Use predict() to make a 1-step forecast
predict_AR <- predict(AR_fit)

# Obtain the 1-step forecast using $pred[1]

predict_AR$pred[1]
# Use predict to make 1-step through 10-step forecasts
predict(AR_fit, n.ahead = 10)

# Run to plot the Nile series plus the forecast and 95% prediction intervals
ts.plot(Nile, xlim = c(1871, 1980))
AR_forecast <- predict(AR_fit, n.ahead = 10)$pred
AR_forecast_se <- predict(AR_fit, n.ahead = 10)$se
points(AR_forecast, type = "l", col = 2)
points(AR_forecast - 2*AR_forecast_se, type = "l", col = 2, lty = 2)
points(AR_forecast + 2*AR_forecast_se, type = "l", col = 2, lty = 2)
```
